# -*- coding: utf-8 -*-
"""Book.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Iw1xqN6sjtx9frwfaO90ltGUg5_uJhQI
"""

!pip install playwright beautifulsoup4 requests chromadb openai google-generativeai numpy pandas matplotlib seaborn
!playwright install chromium
!apt-get update
!apt-get install -y xvfb

import os
import json
import time
import asyncio
import requests
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import pandas as pd
import numpy as np
from dataclasses import dataclass, asdict
from pathlib import Path
import base64
from io import BytesIO
from PIL import Image
import matplotlib.pyplot as plt
import seaborn as sns


from playwright.async_api import async_playwright
from bs4 import BeautifulSoup


import chromadb
from chromadb.config import Settings
import google.generativeai as genai


from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import KMeans

@dataclass
class Chapter:
    id: str
    title: str
    original_content: str
    spun_content: str = ""
    reviewed_content: str = ""
    final_content: str = ""
    version: int = 1
    created_at: datetime = None
    updated_at: datetime = None
    human_feedback: List[str] = None

    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now()
        if self.updated_at is None:
            self.updated_at = datetime.now()
        if self.human_feedback is None:
            self.human_feedback = []

@dataclass
class WorkflowConfig:
    source_url: str = "https://en.wikisource.org/wiki/The_Gates_of_Morning/Book_1/Chapter_1"
    gemini_api_key: str = ""
    output_dir: str = "/content/book_workflow"
    max_iterations: int = 3
    similarity_threshold: float = 0.8

class WebScraper:

    def __init__(self, config: WorkflowConfig):
        self.config = config
        self.output_dir = Path(config.output_dir)
        self.output_dir.mkdir(exist_ok=True)

    async def scrape_content(self, url: str) -> Tuple[str, str, bytes]:
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()

            try:
                await page.goto(url, wait_until='networkidle')

                content = await page.content()
                soup = BeautifulSoup(content, 'html.parser')

                main_content = soup.find('div', {'class': 'mw-parser-output'})
                if main_content:
                    text_content = main_content.get_text(strip=True, separator='\n')
                else:
                    text_content = soup.get_text(strip=True, separator='\n')

                title_elem = soup.find('h1', {'class': 'firstHeading'})
                title = title_elem.get_text(strip=True) if title_elem else "Unknown Chapter"

                screenshot = await page.screenshot(full_page=True)

                screenshot_path = self.output_dir / f"screenshot_{int(time.time())}.png"
                with open(screenshot_path, 'wb') as f:
                    f.write(screenshot)

                print(f" Scraped content: {len(text_content)} characters")
                print(f" Screenshot saved: {screenshot_path}")

                return title, text_content, screenshot

            except Exception as e:
                print(f" Error scraping {url}: {e}")
                return "", "", b""
            finally:
                await browser.close()

import google.generativeai as genai
from typing import Optional

class AIProcessor:
    """Handles AI writing and reviewing using Gemini"""

    def __init__(self, config: WorkflowConfig):
        self.config = config
        if config.gemini_api_key:
            try:
                genai.configure(api_key=config.gemini_api_key)
                self.model = genai.GenerativeModel(model_name="gemini-pro")
                print("‚úÖ Gemini model initialized successfully.")
            except Exception as e:
                print(f"‚ùå Failed to initialize Gemini model: {e}")
                self.model = None
        else:
            self.model = None
            print("‚ö†Ô∏è Warning: No Gemini API key provided. Using mock responses.")

    def spin_content(self, original_content: str, chapter_title: str) -> str:
        if not self.model:
            return self._mock_spin_content(original_content, chapter_title)

        prompt = f"""
You are an expert creative writer. Your task is to rewrite the following chapter
while maintaining its core narrative and themes. Make it more engaging, modern,
and accessible while preserving the original story structure.

Chapter Title: {chapter_title}

Original Content:
{original_content[:3000]}...

Please provide a complete rewrite that:
1. Maintains the original plot and character development
2. Uses more engaging and modern prose
3. Adds vivid descriptions and dialogue where appropriate
4. Keeps the same chapter structure
5. Maintains approximately the same length

Rewritten Chapter:
"""

        try:
            response = self.model.generate_content([prompt])
            return response.text
        except Exception as e:
            print(f"‚ùå Error in AI spinning: {e}")
            return self._mock_spin_content(original_content, chapter_title)

    def review_content(self, spun_content: str, original_content: str, chapter_title: str) -> str:
        if not self.model:
            return self._mock_review_content(spun_content, chapter_title)

        prompt = f"""
You are an expert editor and literary critic. Review the following rewritten chapter
and provide an improved version. Focus on:

1. Narrative flow and pacing
2. Character consistency
3. Prose quality and readability
4. Dialogue authenticity
5. Maintaining the original story essence

Chapter Title: {chapter_title}

Rewritten Content to Review:
{spun_content[:3000]}...

Original Reference:
{original_content[:1500]}...

Please provide your reviewed and improved version:
"""

        try:
            response = self.model.generate_content([prompt])
            return response.text
        except Exception as e:
            print(f"‚ùå Error in AI reviewing: {e}")
            return self._mock_review_content(spun_content, chapter_title)

    def _mock_spin_content(self, original_content: str, chapter_title: str) -> str:
        return f"""
[AI SPUN VERSION - MOCK]

Title: {chapter_title} (Reimagined)

This is a creative reinterpretation of the original chapter. The AI writer has
taken the core narrative elements and transformed them with modern prose,
enhanced dialogue, and vivid descriptions.

Key improvements:
- More engaging opening
- Enhanced character development
- Improved pacing and flow
- Contemporary language while maintaining period authenticity

Original length: {len(original_content)} characters
Spun content maintains similar structure and themes while offering fresh perspective.

[This would be the full rewritten chapter in a real implementation]
"""

    def _mock_review_content(self, spun_content: str, chapter_title: str) -> str:
        return f"""
[AI REVIEWED VERSION - MOCK]

Title: {chapter_title} (Reviewed & Refined)

After editorial review, the following improvements have been made:

1. Narrative Flow: Enhanced transitions between scenes
2. Character Development: Strengthened character motivations
3. Prose Quality: Refined sentence structure and word choice
4. Dialogue: Made conversations more natural and authentic
5. Consistency: Ensured alignment with original themes

This reviewed version represents the optimal balance between creative
reinterpretation and faithful adaptation of the source material.

[This would be the full reviewed chapter in a real implementation]
"""

!pip install -U google-generativeai

import google.generativeai as genai
from typing import Optional
import time
import logging

class AIProcessor:
    """Handles AI writing and reviewing using Gemini with proper error handling"""

    def __init__(self, config):
        self.config = config
        self.model = None
        self.setup_gemini()

    def setup_gemini(self):
        """Initialize Gemini with proper model names and error handling"""
        if not self.config.gemini_api_key:
            print("‚ö†Ô∏è Warning: No Gemini API key provided. Using mock responses.")
            return

        try:
            genai.configure(api_key=self.config.gemini_api_key)

            # Use the correct model name - gemini-1.5-flash is more stable
            # Alternative models: gemini-1.5-pro, gemini-1.0-pro
            model_name = "gemini-1.5-flash"

            self.model = genai.GenerativeModel(
                model_name=model_name,
                generation_config=genai.types.GenerationConfig(
                    candidate_count=1,
                    max_output_tokens=8192,
                    temperature=0.7,
                )
            )

            # Test the connection
            test_response = self.model.generate_content("Hello")
            print(f"‚úÖ Gemini model ({model_name}) initialized and tested successfully.")

        except Exception as e:
            print(f"‚ùå Failed to initialize Gemini model: {e}")
            print("üîß Falling back to mock responses.")
            self.model = None

    def spin_content(self, original_content: str, chapter_title: str, feedback: str = "") -> str:
        """Rewrite content with AI, incorporating feedback"""
        if not self.model:
            return self._mock_spin_content(original_content, chapter_title)

        # Build prompt with feedback if provided
        feedback_section = f"\n\nAdditional feedback to incorporate:\n{feedback}" if feedback else ""

        prompt = f"""You are an expert creative writer and editor. Your task is to rewrite the following chapter while maintaining its core narrative and themes.

Chapter Title: {chapter_title}

Requirements:
1. Maintain the original plot, characters, and story structure
2. Use engaging, modern prose that flows naturally
3. Add vivid descriptions and realistic dialogue
4. Preserve the historical/literary context and tone
5. Keep similar length to original (around {len(original_content)} characters)
6. Ensure smooth transitions between scenes{feedback_section}

Original Content:
{original_content}

Please provide your complete rewritten chapter:"""

        return self._generate_with_retry(prompt, "spinning")

    def review_content(self, spun_content: str, original_content: str, chapter_title: str, feedback: str = "") -> str:
        """Review and improve the spun content"""
        if not self.model:
            return self._mock_review_content(spun_content, chapter_title)

        feedback_section = f"\n\nSpecific feedback to address:\n{feedback}" if feedback else ""

        prompt = f"""You are an expert literary editor. Review and improve the following rewritten chapter, focusing on quality and readability.

Chapter Title: {chapter_title}

Editorial Focus Areas:
1. Narrative flow and pacing
2. Character consistency and development
3. Prose quality and sentence structure
4. Dialogue authenticity and naturalness
5. Maintaining story essence and themes
6. Grammar, style, and readability{feedback_section}

Rewritten Content to Review:
{spun_content}

Original Reference (for context):
{original_content[:2000]}...

Please provide your edited and improved version:"""

        return self._generate_with_retry(prompt, "reviewing")

    def _generate_with_retry(self, prompt: str, operation: str, max_retries: int = 3) -> str:
        """Generate content with retry logic and rate limiting"""
        for attempt in range(max_retries):
            try:
                # Add delay to respect rate limits
                if attempt > 0:
                    wait_time = 2 ** attempt  # Exponential backoff
                    print(f"‚è≥ Retrying {operation} in {wait_time} seconds...")
                    time.sleep(wait_time)

                response = self.model.generate_content(prompt)

                if response.text:
                    return response.text
                else:
                    raise Exception("Empty response from model")

            except Exception as e:
                print(f"‚ùå Error in AI {operation} (attempt {attempt + 1}): {e}")

                if attempt == max_retries - 1:
                    print(f"üîß Max retries reached for {operation}. Using mock content.")
                    if operation == "spinning":
                        return self._mock_spin_content("", "Error Recovery")
                    else:
                        return self._mock_review_content("", "Error Recovery")

        return "Error: Could not generate content"

    def _mock_spin_content(self, original_content: str, chapter_title: str) -> str:
        return f"""[MOCK AI SPUN VERSION]

Title: {chapter_title} (Creatively Reinterpreted)

This is a creative reinterpretation of the original chapter. In a fully functional system, the AI would transform the source material with:

‚Ä¢ Enhanced narrative engagement and modern prose style
‚Ä¢ Deeper character development and motivations
‚Ä¢ Improved dialogue that feels natural and authentic
‚Ä¢ Vivid descriptions that immerse the reader
‚Ä¢ Smooth pacing and seamless scene transitions
‚Ä¢ Contemporary language while preserving historical context

Original content length: {len(original_content)} characters

The rewritten chapter would maintain the core story structure and themes while making the content more accessible and engaging for modern readers. Key plot points, character arcs, and thematic elements would remain faithful to the source while benefiting from enhanced storytelling techniques.

[In production, this would contain the complete rewritten chapter]"""

    def _mock_review_content(self, spun_content: str, chapter_title: str) -> str:
        return f"""[MOCK AI REVIEWED VERSION]

Title: {chapter_title} (Editorially Refined)

Following comprehensive editorial review, this version incorporates:

STRUCTURAL IMPROVEMENTS:
‚Ä¢ Enhanced narrative flow with smoother transitions
‚Ä¢ Balanced pacing throughout all scenes
‚Ä¢ Consistent point of view and tense usage

CHARACTER & DIALOGUE:
‚Ä¢ Strengthened character voice and authenticity
‚Ä¢ More natural dialogue patterns and speech
‚Ä¢ Clearer character motivations and development

PROSE QUALITY:
‚Ä¢ Refined sentence structure and rhythm
‚Ä¢ Eliminated redundancy and improved clarity
‚Ä¢ Enhanced descriptive language and imagery

THEMATIC CONSISTENCY:
‚Ä¢ Maintained alignment with original themes
‚Ä¢ Preserved historical/literary context
‚Ä¢ Ensured story coherence and impact

This reviewed version represents the optimal synthesis of creative reinterpretation and editorial excellence, ready for final publication.

[In production, this would contain the complete edited chapter]"""

    def get_model_info(self) -> dict:
        """Return information about the current model setup"""
        return {
            "model_available": self.model is not None,
            "model_name": "gemini-1.5-flash" if self.model else "mock",
            "api_configured": bool(self.config.gemini_api_key),
            "status": "operational" if self.model else "mock_mode"
        }

class HumanInTheLoop:

    def __init__(self, config: WorkflowConfig):
        self.config = config
        self.feedback_history = []

    def get_human_feedback(self, chapter: Chapter, stage: str) -> str:
        print(f"\n{'='*60}")
        print(f"HUMAN REVIEW REQUIRED - {stage.upper()}")
        print(f"{'='*60}")
        print(f"Chapter: {chapter.title}")
        print(f"Version: {chapter.version}")
        print(f"Stage: {stage}")
        print(f"{'='*60}")

        if stage == "spinning":
            content_to_review = chapter.spun_content[:500] + "..."
        elif stage == "reviewing":
            content_to_review = chapter.reviewed_content[:500] + "..."
        else:
            content_to_review = chapter.final_content[:500] + "..."

        print(f"Content Preview:\n{content_to_review}")
        print(f"{'='*60}")

        feedback = self._simulate_human_feedback(chapter, stage)

        chapter.human_feedback.append({
            'stage': stage,
            'feedback': feedback,
            'timestamp': datetime.now().isoformat(),
            'version': chapter.version
        })

        return feedback

    def _simulate_human_feedback(self, chapter: Chapter, stage: str) -> str:
        feedback_options = {
            "spinning": [
                "Good creative adaptation, but needs more dialogue in the opening scene.",
                "The pacing feels rushed in the middle section. Please expand the character development.",
                "Excellent work! Ready for review stage.",
                "The tone doesn't quite match the original. Please revise with more formal language."
            ],
            "reviewing": [
                "Much improved! The dialogue flows better now.",
                "Still needs work on the ending. It feels abrupt.",
                "Perfect balance of creativity and faithfulness to the original.",
                "The character motivations could be clearer in the second half."
            ],
            "final": [
                "Approved for publication!",
                "Minor formatting issues, but content is excellent.",
                "Ready to go live!",
                "One more revision needed on the conclusion."
            ]
        }

        feedback_list = feedback_options.get(stage, ["Looks good!"])
        feedback_index = (chapter.version - 1) % len(feedback_list)
        selected_feedback = feedback_list[feedback_index]

        print(f"Simulated Human Feedback: {selected_feedback}")
        return selected_feedback

    def should_continue_iteration(self, feedback: str) -> bool:
        approval_keywords = ["approved", "ready", "excellent", "perfect", "go live"]
        return not any(keyword in feedback.lower() for keyword in approval_keywords)

class RLSearchAlgorithm:

    def __init__(self):
        self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
        self.content_vectors = None
        self.content_metadata = []
        self.search_history = []
        self.reward_matrix = {}

    def index_content(self, chapters: List[Chapter]):
        texts = []
        metadata = []

        for chapter in chapters:
            content_versions = [
                chapter.original_content,
                chapter.spun_content,
                chapter.reviewed_content,
                chapter.final_content
            ]

            for i, content in enumerate(content_versions):
                if content.strip():
                    texts.append(content)
                    metadata.append({
                        'chapter_id': chapter.id,
                        'title': chapter.title,
                        'version': chapter.version,
                        'content_type': ['original', 'spun', 'reviewed', 'final'][i],
                        'created_at': chapter.created_at,
                        'updated_at': chapter.updated_at
                    })

        if texts:
            self.content_vectors = self.vectorizer.fit_transform(texts)
            self.content_metadata = metadata
            print(f" Indexed {len(texts)} content pieces for search")

    def search(self, query: str, top_k: int = 5) -> List[Dict]:
        if self.content_vectors is None:
            return []

        query_vector = self.vectorizer.transform([query])

        similarities = cosine_similarity(query_vector, self.content_vectors).flatten()

        scored_results = []
        for i, similarity in enumerate(similarities):
            metadata = self.content_metadata[i]

            reward = self._calculate_reward(metadata, query)

            final_score = similarity * 0.7 + reward * 0.3

            scored_results.append({
                'metadata': metadata,
                'similarity': similarity,
                'reward': reward,
                'final_score': final_score,
                'content_preview': self._get_content_preview(i)
            })

        scored_results.sort(key=lambda x: x['final_score'], reverse=True)

        self._record_search(query, scored_results[:top_k])

        return scored_results[:top_k]

    def _calculate_reward(self, metadata: Dict, query: str) -> float:
        key = f"{metadata['chapter_id']}_{metadata['content_type']}"

        if key not in self.reward_matrix:
            self.reward_matrix[key] = {
                'clicks': 0,
                'relevance_ratings': [],
                'recency_bonus': 0.0
            }

        reward_data = self.reward_matrix[key]

        click_reward = min(reward_data['clicks'] * 0.1, 0.5)

        relevance_reward = np.mean(reward_data['relevance_ratings']) if reward_data['relevance_ratings'] else 0.0

        recency_reward = reward_data['recency_bonus']

        type_rewards = {'final': 0.4, 'reviewed': 0.3, 'spun': 0.2, 'original': 0.1}
        type_reward = type_rewards.get(metadata['content_type'], 0.0)

        return (click_reward + relevance_reward + recency_reward + type_reward) / 4.0

    def _get_content_preview(self, index: int) -> str:
        return f"Content preview for index {index}..."

    def _record_search(self, query: str, results: List[Dict]):
        search_record = {
            'query': query,
            'timestamp': datetime.now().isoformat(),
            'results_count': len(results),
            'top_result': results[0]['metadata'] if results else None
        }
        self.search_history.append(search_record)

    def update_reward(self, chapter_id: str, content_type: str, action: str, value: float = 1.0):
        key = f"{chapter_id}_{content_type}"

        if key not in self.reward_matrix:
            self.reward_matrix[key] = {
                'clicks': 0,
                'relevance_ratings': [],
                'recency_bonus': 0.0
            }

        if action == 'click':
            self.reward_matrix[key]['clicks'] += 1
        elif action == 'rate':
            self.reward_matrix[key]['relevance_ratings'].append(value)
        elif action == 'recency':
            self.reward_matrix[key]['recency_bonus'] = value

from chromadb import PersistentClient

class ContentVectorStore:

    def __init__(self, config: WorkflowConfig):
        self.config = config
        persist_path = str(Path(config.output_dir) / "chroma_db")

        self.client = PersistentClient(path=persist_path)

        self.collection = self.client.get_or_create_collection(
            name="book_chapters",
            metadata={"hnsw:space": "cosine"}
        )

        print(f" ChromaDB initialized with collection: {self.collection.name}")

    def store_chapter(self, chapter: Chapter):
        content_versions = [
            ("original", chapter.original_content),
            ("spun", chapter.spun_content),
            ("reviewed", chapter.reviewed_content),
            ("final", chapter.final_content)
        ]

        documents = []
        metadatas = []
        ids = []

        for content_type, content in content_versions:
            if content.strip():
                documents.append(content)
                metadatas.append({
                    "chapter_id": chapter.id,
                    "title": chapter.title,
                    "content_type": content_type,
                    "version": str(chapter.version),
                    "created_at": chapter.created_at.isoformat(),
                    "updated_at": chapter.updated_at.isoformat(),
                    "human_feedback_count": str(len(chapter.human_feedback))
                })
                ids.append(f"{chapter.id}_{content_type}_v{chapter.version}")

        if documents:
            self.collection.add(
                documents=documents,
                metadatas=metadatas,
                ids=ids
            )
            print(f" Stored {len(documents)} content versions for chapter: {chapter.title}")

    def search_chapters(self, query: str, n_results: int = 5, content_type: str = None) -> List[Dict]:
        where_clause = {}
        if content_type:
            where_clause["content_type"] = content_type

        results = self.collection.query(
            query_texts=[query],
            n_results=n_results,
            where=where_clause if where_clause else None
        )

        formatted_results = []
        if results['documents'] and results['documents'][0]:
            for i in range(len(results['documents'][0])):
                formatted_results.append({
                    'id': results['ids'][0][i],
                    'content': results['documents'][0][i][:500] + "...",
                    'metadata': results['metadatas'][0][i],
                    'distance': results['distances'][0][i] if results['distances'] else 0.0
                })

        return formatted_results

    def get_chapter_versions(self, chapter_id: str) -> List[Dict]:
        results = self.collection.query(
            query_texts=[""],
            n_results=100,
            where={"chapter_id": chapter_id}
        )

        versions = []
        if results['documents'] and results['documents'][0]:
            for i in range(len(results['documents'][0])):
                versions.append({
                    'id': results['ids'][0][i],
                    'content': results['documents'][0][i],
                    'metadata': results['metadatas'][0][i]
                })

        return sorted(versions, key=lambda x: x['metadata']['content_type'])

    def persist(self):
        # self.client.persist()
        print(" ChromaDB changes are auto-persisted with PersistentClient.")

class BookPublicationWorkflow:

    def __init__(self, config: WorkflowConfig):
        self.config = config
        self.scraper = WebScraper(config)
        self.ai_processor = AIProcessor(config)
        self.human_loop = HumanInTheLoop(config)
        self.vector_store = ContentVectorStore(config)
        self.search_algorithm = RLSearchAlgorithm()
        self.chapters = []

        self.output_dir = Path(config.output_dir)
        self.output_dir.mkdir(exist_ok=True)
        (self.output_dir / "chapters").mkdir(exist_ok=True)
        (self.output_dir / "screenshots").mkdir(exist_ok=True)
        (self.output_dir / "reports").mkdir(exist_ok=True)

    async def process_chapter(self, url: str) -> Chapter:
        print(f"\n Starting workflow for: {url}")

        print("\n Step 1: Scraping content...")
        title, content, screenshot = await self.scraper.scrape_content(url)

        if not content:
            raise Exception("Failed to scrape content")

        chapter = Chapter(
            id=f"chapter_{len(self.chapters) + 1}",
            title=title,
            original_content=content
        )

        print("\n Step 2: AI Content Spinning...")
        chapter.spun_content = self.ai_processor.spin_content(content, title)

        print("\n Step 3: Human feedback on spinning...")
        spin_feedback = self.human_loop.get_human_feedback(chapter, "spinning")

        iteration_count = 0
        while (self.human_loop.should_continue_iteration(spin_feedback) and
               iteration_count < self.config.max_iterations):
            iteration_count += 1
            print(f"\n Iteration {iteration_count} on spinning...")
            chapter.spun_content = self.ai_processor.spin_content(content, title)
            spin_feedback = self.human_loop.get_human_feedback(chapter, "spinning")
            chapter.version += 1

        print("\n Step 4: AI Content Review...")
        chapter.reviewed_content = self.ai_processor.review_content(
            chapter.spun_content, chapter.original_content, title
        )

        print("\n Step 5: Human feedback on review...")
        review_feedback = self.human_loop.get_human_feedback(chapter, "reviewing")

        iteration_count = 0
        while (self.human_loop.should_continue_iteration(review_feedback) and
               iteration_count < self.config.max_iterations):
            iteration_count += 1
            print(f"\n Iteration {iteration_count} on review...")
            chapter.reviewed_content = self.ai_processor.review_content(
                chapter.spun_content, chapter.original_content, title
            )
            review_feedback = self.human_loop.get_human_feedback(chapter, "reviewing")
            chapter.version += 1

        print("\n Step 6: Finalizing content...")
        chapter.final_content = chapter.reviewed_content
        chapter.updated_at = datetime.now()

        final_feedback = self.human_loop.get_human_feedback(chapter, "final")

        print("\n Step 7: Storing in vector database...")
        self.vector_store.store_chapter(chapter)

        self._save_chapter_to_file(chapter)

        self.chapters.append(chapter)

        print(f"\n Chapter processing complete: {chapter.title}")
        return chapter

    def _save_chapter_to_file(self, chapter: Chapter):
        chapter_data = asdict(chapter)
        chapter_data['created_at'] = chapter.created_at.isoformat()
        chapter_data['updated_at'] = chapter.updated_at.isoformat()

        file_path = self.output_dir / "chapters" / f"{chapter.id}_v{chapter.version}.json"
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(chapter_data, f, indent=2, ensure_ascii=False)

        print(f" Chapter saved to: {file_path}")

    def update_search_index(self):
        self.search_algorithm.index_content(self.chapters)

    def search_content(self, query: str, method: str = "vector") -> List[Dict]:
        if method == "vector":
            return self.vector_store.search_chapters(query)
        elif method == "rl":
            return self.search_algorithm.search(query)
        else:
            raise ValueError("Method must be 'vector' or 'rl'")

    def generate_workflow_report(self) -> str:
        report = f"""
# Book Publication Workflow Report
Generated: {datetime.now().isoformat()}

## Summary
- Total chapters processed: {len(self.chapters)}
- Total content pieces in vector store: {self.vector_store.collection.count()}
- Search algorithm indexed: {len(self.search_algorithm.content_metadata)} pieces

## Chapter Details
"""

        for chapter in self.chapters:
            report += f"""
### {chapter.title}
- ID: {chapter.id}
- Version: {chapter.version}
- Created: {chapter.created_at}
- Updated: {chapter.updated_at}
- Human feedback iterations: {len(chapter.human_feedback)}
- Original content length: {len(chapter.original_content)} chars
- Final content length: {len(chapter.final_content)} chars

"""

        report += f"""
## Search Performance
- Total searches performed: {len(self.search_algorithm.search_history)}
- Reward matrix entries: {len(self.search_algorithm.reward_matrix)}

## Vector Store Statistics
- Collection name: {self.vector_store.collection.name}
- Total documents: {self.vector_store.collection.count()}

## Configuration
- Source URL: {self.config.source_url}
- Max iterations: {self.config.max_iterations}
- Output directory: {self.config.output_dir}
"""

        report_path = self.output_dir / "reports" / f"workflow_report_{int(time.time())}.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)

        print(f"Report saved to: {report_path}")
        return report

config = WorkflowConfig(
    source_url="https://en.wikisource.org/wiki/The_Gates_of_Morning/Book_1/Chapter_1",
    gemini_api_key="YOUR_API_KEY",
    output_dir="/content/book_workflow",
    max_iterations=2,
    similarity_threshold=0.8
)

workflow = BookPublicationWorkflow(config)

print("üéØ Book Publication Workflow Initialized!")
print(f"üìÅ Output directory: {config.output_dir}")
print(f"üîó Source URL: {config.source_url}")

async def run_main_workflow():
    try:
        chapter = await workflow.process_chapter(config.source_url)

        print("\n Updating search index...")
        workflow.update_search_index()

        print("\n Demonstrating search capabilities...")

        vector_results = workflow.search_content("morning gates chapter", method="vector")
        print(f"Vector search found {len(vector_results)} results")

        rl_results = workflow.search_content("morning gates chapter", method="rl")
        print(f"RL search found {len(rl_results)} results")

        print("\n Generating workflow report...")
        report = workflow.generate_workflow_report()

        print("\n Persisting data...")
        workflow.vector_store.persist()

        print("\n Workflow completed successfully!")

        return chapter, report

    except Exception as e:
        print(f" Workflow failed: {e}")
        raise

chapter_result, workflow_report = await run_main_workflow()

